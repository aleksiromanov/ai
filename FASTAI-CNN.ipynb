{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with the Fastai's CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on https://medium.com/deena-does-data-science/train-a-cnn-with-the-fastai-library-88712a68e4d4\n",
    "- But the goal is, instead of the canser dataset, use USD/EUR candlestick captures from https://finviz.com/forex_charts.ashx?t=EURUSD&tf=m5. Labels are BUY and SELL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python 3.7.1\n",
      "\n",
      "Current directory /home/jovyan/work\n",
      "\n",
      "Available image data folders:\n",
      "44M\tdata/images/chiffon\n",
      "67M\tdata/images/denim\n",
      "84M\tdata/images/faux_fur\n",
      "60M\tdata/images/faux_leather\n",
      "73M\tdata/images/lace\n",
      "56M\tdata/images/linen\n",
      "66M\tdata/images/satin\n",
      "124M\tdata/images/sequin\n",
      "54M\tdata/images/velvet\n"
     ]
    }
   ],
   "source": [
    "!echo Using `python --version`\n",
    "!echo\n",
    "!echo Current directory `pwd`\n",
    "!echo\n",
    "!echo Available image data folders:\n",
    "!du -sh data/images/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A regular list of some images\n",
    "\n",
    "fpaths = list(Path('./data/images/').rglob('*.jpg'))\n",
    "fstems = [fp.stem for fp in fpaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpaths</th>\n",
       "      <th>fstems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/images/denim/00000343.jpg</td>\n",
       "      <td>00000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/images/denim/00000076.jpg</td>\n",
       "      <td>00000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/images/denim/00000170.jpg</td>\n",
       "      <td>00000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/images/denim/00000103.jpg</td>\n",
       "      <td>00000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/images/denim/00000069.jpg</td>\n",
       "      <td>00000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fpaths    fstems\n",
       "0  data/images/denim/00000343.jpg  00000343\n",
       "1  data/images/denim/00000076.jpg  00000076\n",
       "2  data/images/denim/00000170.jpg  00000170\n",
       "3  data/images/denim/00000103.jpg  00000103\n",
       "4  data/images/denim/00000069.jpg  00000069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Series of the same images\n",
    "\n",
    "df = pd.concat([pd.Series(fpaths, name='fpaths'), \n",
    "                pd.Series(fstems, name='fstems')], \n",
    "               axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpaths</th>\n",
       "      <th>fstems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/images/denim/00000343.jpg</td>\n",
       "      <td>00000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/images/denim/00000076.jpg</td>\n",
       "      <td>00000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/images/denim/00000170.jpg</td>\n",
       "      <td>00000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/images/denim/00000103.jpg</td>\n",
       "      <td>00000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/images/denim/00000069.jpg</td>\n",
       "      <td>00000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fpaths    fstems\n",
       "0  data/images/denim/00000343.jpg  00000343\n",
       "1  data/images/denim/00000076.jpg  00000076\n",
       "2  data/images/denim/00000170.jpg  00000170\n",
       "3  data/images/denim/00000103.jpg  00000103\n",
       "4  data/images/denim/00000069.jpg  00000069"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'fpaths' column from the object-type the string \n",
    "\n",
    "df['fpaths'] = df['fpaths'].apply(lambda x: str(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpaths</th>\n",
       "      <th>fstems</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/images/denim/00000343.jpg</td>\n",
       "      <td>00000343</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/images/denim/00000076.jpg</td>\n",
       "      <td>00000076</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/images/denim/00000170.jpg</td>\n",
       "      <td>00000170</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/images/denim/00000103.jpg</td>\n",
       "      <td>00000103</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/images/denim/00000069.jpg</td>\n",
       "      <td>00000069</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fpaths    fstems  label\n",
       "0  data/images/denim/00000343.jpg  00000343  denim\n",
       "1  data/images/denim/00000076.jpg  00000076  denim\n",
       "2  data/images/denim/00000170.jpg  00000170  denim\n",
       "3  data/images/denim/00000103.jpg  00000103  denim\n",
       "4  data/images/denim/00000069.jpg  00000069  denim"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make *label* column\n",
    "\n",
    "df['label'] = df['fpaths'].str.split('/', expand=True)[2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",fpaths,fstems,label\r\n",
      "0,data/images/denim/00000343.jpg,00000343,denim\r\n",
      "1,data/images/denim/00000076.jpg,00000076,denim\r\n",
      "2,data/images/denim/00000170.jpg,00000170,denim\r\n",
      "3,data/images/denim/00000103.jpg,00000103,denim\r\n",
      "4,data/images/denim/00000069.jpg,00000069,denim\r\n",
      "5,data/images/denim/00000182.jpg,00000182,denim\r\n",
      "6,data/images/denim/00000019.jpg,00000019,denim\r\n",
      "7,data/images/denim/00000434.jpg,00000434,denim\r\n",
      "8,data/images/denim/00000092.jpg,00000092,denim\r\n"
     ]
    }
   ],
   "source": [
    "# Export the dataframe to a csv file\n",
    "\n",
    "df.to_csv('/tmp/mydataframe.csv')\n",
    "!head /tmp/mydataframe.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fpaths</th>\n",
       "      <th>fstems</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/images/denim/00000343.jpg</td>\n",
       "      <td>343</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/images/denim/00000076.jpg</td>\n",
       "      <td>76</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>data/images/denim/00000170.jpg</td>\n",
       "      <td>170</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data/images/denim/00000103.jpg</td>\n",
       "      <td>103</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>data/images/denim/00000069.jpg</td>\n",
       "      <td>69</td>\n",
       "      <td>denim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          fpaths  fstems  label\n",
       "0           0  data/images/denim/00000343.jpg     343  denim\n",
       "1           1  data/images/denim/00000076.jpg      76  denim\n",
       "2           2  data/images/denim/00000170.jpg     170  denim\n",
       "3           3  data/images/denim/00000103.jpg     103  denim\n",
       "4           4  data/images/denim/00000069.jpg      69  denim"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv to the dataframe\n",
    "\n",
    "df = pd.read_csv('/tmp/mydataframe.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make a databunch (a set of datasets and dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageList (4655 items)\n",
       "Image (3, 480, 480),Image (3, 800, 800),Image (3, 580, 540),Image (3, 1500, 1000),Image (3, 704, 550)\n",
       "Path: ."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.image import *\n",
    "from fastai.vision.data import  * \n",
    "\n",
    "data = ImageList.from_df(path='.', df=df, cols='fpaths')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemLists;\n",
       "\n",
       "Train: ImageList (3724 items)\n",
       "Image (3, 480, 480),Image (3, 580, 540),Image (3, 1500, 1000),Image (3, 498, 375),Image (3, 560, 420)\n",
       "Path: .;\n",
       "\n",
       "Valid: ImageList (931 items)\n",
       "Image (3, 563, 450),Image (3, 417, 300),Image (3, 400, 400),Image (3, 480, 320),Image (3, 465, 370)\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.split_by_rand_pct(valid_pct=0.2, seed=10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelLists;\n",
       "\n",
       "Train: LabelList (3724 items)\n",
       "x: ImageList\n",
       "Image (3, 480, 480),Image (3, 580, 540),Image (3, 1500, 1000),Image (3, 498, 375),Image (3, 560, 420)\n",
       "y: CategoryList\n",
       "denim,denim,denim,denim,denim\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (931 items)\n",
       "x: ImageList\n",
       "Image (3, 563, 450),Image (3, 417, 300),Image (3, 400, 400),Image (3, 480, 320),Image (3, 465, 370)\n",
       "y: CategoryList\n",
       "denim,faux_leather,denim,sequin,denim\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.label_from_df(cols='label')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.transform(tfms=tfms, size=49, padding_mode=zeros)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=True, \n",
    "                      flip_vert=True, \n",
    "                      max_rotate=4., \n",
    "                      max_zoom=1.1, \n",
    "                      max_lighting=0.2, \n",
    "                      max_warp=0., \n",
    "                      p_affine=0.75, \n",
    "                      p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py:262: UserWarning: It's not possible to collate samples of your dataset together in a batch.\n",
      "Shapes of the inputs/targets:\n",
      "[[torch.Size([3, 480, 360]), torch.Size([3, 589, 408]), torch.Size([3, 1020, 640]), torch.Size([3, 1040, 800]), torch.Size([3, 600, 450]), torch.Size([3, 551, 343]), torch.Size([3, 699, 1045]), torch.Size([3, 1020, 640]), torch.Size([3, 1746, 1600]), torch.Size([3, 800, 800]), torch.Size([3, 417, 300]), torch.Size([3, 500, 384]), torch.Size([3, 496, 331]), torch.Size([3, 700, 600]), torch.Size([3, 466, 466]), torch.Size([3, 711, 540]), torch.Size([3, 1596, 1200]), torch.Size([3, 530, 400]), torch.Size([3, 400, 300]), torch.Size([3, 336, 224]), torch.Size([3, 3297, 5125]), torch.Size([3, 1530, 1020]), torch.Size([3, 225, 164]), torch.Size([3, 427, 295]), torch.Size([3, 900, 600]), torch.Size([3, 632, 500]), torch.Size([3, 445, 257]), torch.Size([3, 225, 225]), torch.Size([3, 1370, 1050]), torch.Size([3, 1200, 800]), torch.Size([3, 466, 466]), torch.Size([3, 2400, 3200]), torch.Size([3, 435, 290]), torch.Size([3, 480, 360]), torch.Size([3, 250, 275]), torch.Size([3, 350, 309]), torch.Size([3, 600, 450]), torch.Size([3, 300, 231]), torch.Size([3, 1066, 1600]), torch.Size([3, 410, 215]), torch.Size([3, 384, 256]), torch.Size([3, 1000, 1000]), torch.Size([3, 360, 270]), torch.Size([3, 728, 1000]), torch.Size([3, 708, 1000]), torch.Size([3, 730, 480]), torch.Size([3, 1020, 640]), torch.Size([3, 522, 522]), torch.Size([3, 720, 1280]), torch.Size([3, 586, 586]), torch.Size([3, 445, 334]), torch.Size([3, 1200, 800]), torch.Size([3, 600, 800]), torch.Size([3, 560, 420]), torch.Size([3, 960, 640]), torch.Size([3, 845, 500]), torch.Size([3, 1020, 640]), torch.Size([3, 448, 448]), torch.Size([3, 406, 325]), torch.Size([3, 852, 1280]), torch.Size([3, 1700, 1133]), torch.Size([3, 730, 480]), torch.Size([3, 563, 450]), torch.Size([3, 443, 300]), torch.Size([3, 600, 600]), torch.Size([3, 921, 780]), torch.Size([3, 700, 700]), torch.Size([3, 4031, 2687]), torch.Size([3, 765, 663]), torch.Size([3, 633, 357]), torch.Size([3, 984, 767]), torch.Size([3, 565, 480]), torch.Size([3, 360, 360]), torch.Size([3, 640, 640]), torch.Size([3, 680, 460]), torch.Size([3, 1024, 683]), torch.Size([3, 244, 244]), torch.Size([3, 1013, 620]), torch.Size([3, 374, 258]), torch.Size([3, 480, 320]), torch.Size([3, 324, 324]), torch.Size([3, 900, 600]), torch.Size([3, 270, 340]), torch.Size([3, 426, 320]), torch.Size([3, 1294, 1000]), torch.Size([3, 300, 300]), torch.Size([3, 426, 320]), torch.Size([3, 1530, 1020]), torch.Size([3, 540, 360]), torch.Size([3, 550, 518]), torch.Size([3, 693, 536]), torch.Size([3, 523, 388]), torch.Size([3, 730, 480]), torch.Size([3, 655, 513]), torch.Size([3, 768, 576]), torch.Size([3, 414, 300]), torch.Size([3, 441, 276]), torch.Size([3, 600, 900]), torch.Size([3, 350, 228]), torch.Size([3, 900, 600]), torch.Size([3, 847, 680]), torch.Size([3, 522, 781]), torch.Size([3, 1353, 1000]), torch.Size([3, 2048, 1365]), torch.Size([3, 500, 500]), torch.Size([3, 640, 640]), torch.Size([3, 571, 236]), torch.Size([3, 360, 240]), torch.Size([3, 387, 258]), torch.Size([3, 445, 278]), torch.Size([3, 480, 360]), torch.Size([3, 1060, 795]), torch.Size([3, 1700, 1133]), torch.Size([3, 694, 1800]), torch.Size([3, 300, 300]), torch.Size([3, 631, 647]), torch.Size([3, 383, 230]), torch.Size([3, 536, 384]), torch.Size([3, 417, 300]), torch.Size([3, 453, 371]), torch.Size([3, 800, 560]), torch.Size([3, 650, 650]), torch.Size([3, 632, 474]), torch.Size([3, 449, 800]), torch.Size([3, 580, 578]), torch.Size([3, 2000, 2000]), torch.Size([3, 1000, 1000]), torch.Size([3, 1563, 1200])], [(), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), ()]]\n",
      "  warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (3724 items)\n",
       "x: ImageList\n",
       "Image (3, 480, 480),Image (3, 580, 540),Image (3, 1500, 1000),Image (3, 498, 375),Image (3, 560, 420)\n",
       "y: CategoryList\n",
       "denim,denim,denim,denim,denim\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (931 items)\n",
       "x: ImageList\n",
       "Image (3, 563, 450),Image (3, 417, 300),Image (3, 400, 400),Image (3, 480, 320),Image (3, 465, 370)\n",
       "y: CategoryList\n",
       "denim,faux_leather,denim,sequin,denim\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.databunch(bs=128, num_workers=4)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\", line 121, in data_collate\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 232, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 232, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 209, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 563 and 417 in dimension 2 at /pytorch/aten/src/TH/generic/THTensorMoreMath.cpp:1307\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e888c1afd97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, stats, do_x, do_y)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;34m\"Add normalize transform using `stats` (defaults to `DataBunch.batch_stats`)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can not call normalize twice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/vision/data.py\u001b[0m in \u001b[0;36mbatch_stats\u001b[0;34m(self, funcs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mfuncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mds_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\", line 121, in data_collate\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 232, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 232, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 209, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 563 and 417 in dimension 2 at /pytorch/aten/src/TH/generic/THTensorMoreMath.cpp:1307\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "\n",
    "data = data.normalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
